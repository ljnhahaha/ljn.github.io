---
title: '2023/11/6, Week 9'
date: 2023-11-6
permalink: /posts/2023/11/week9/
tags:
  - video stitch
---

# 《**Stitch it in Time: GAN-Based Facial Editing of Real Videos**》

### Keywords:

temporal coherency

### Motivation:

- problem: GAN based semantic editing tools bring a renaissance in the field of image manipulation, but it is difficult to edit videos due to *temporal coherency*. Train a GAN for video synthesis is challenging and complicated.
- Assume that the initial video is already coherent, we just have to maintain the coherency in synthesized video.
- Inversion method: PTI.
  -  First fine a 'pivot' , then fine-tune the generator's weights.
  - drawback: optimization-based inversion is inconsistent.

- **Innovation**:
  - use an encoder to discover locally consistent pivot
  - design a novel *stitch tuning* operation to stitch the edited crop back to the original video.

### Method:

#### Pipeline:  

temporally consistent alignment, encoder-based inversion, generator tuning, editing, stitching tuning and finally merging the results back into the original frame

#### Alignment:

vanilla alignment: landmarks detection + crop. It will lead to temporal inconsistencies

improved version: landmarks detection + Gaussian low-pass filter over the landmark + crop

#### Inversion:

Optimization-based inversion is susceptible to inconsistencies.

Encoder-based inversion can alleviate this problem when the transitions between inputs are smooth, so we further need a smooth alignment method.

*need to fine-tune the generator for each video, each time with all frames in one video* (computational expensive)

#### Stitching Tuning:

Segment the edited images to produce the segmentation mask $\{ m_i \}^N_{i=1}$, and dilate on each to obtain expand masks $\{ m_i^d \}^N_{i=1}$, and the boundary is denoted as $\{ b_i \}^N_{i=1} = \{ m_i \otimes m_i^d \}^N_{i=1}$ . Fine-tune the generator to constrain the boundary close to raw image and face region close to edited image.

*need to fine-tune the generator for each frame*
