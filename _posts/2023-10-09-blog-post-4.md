---
title: '2023/10/9, Week 5'
date: 2023-10-9
permalink: /posts/2023/10/week5/
tags:
  - Privacy-Preserving
  - rPPG
---

# 《Personalized and Invertible Face De-identification by Disentangled Identity Information Manipulation》

Keywords: de-identification, invertible, controllable manipulation

Recovery Process:
$$
\begin{align*}
M^{-1}(z_{new}, p, d) &= \frac{z_{new} - z_{r} \cdot sin\theta}{cos\theta - A \cdot sin\theta} \\   &= \frac{z_{new} - z_{r} \cdot sin\theta}{(z_{new} - z_r \cdot sin\theta)\cdot z_{new}} \cdot cos\theta \\ &=z_{id} \cdot \frac{cos\theta}{z_{id} \cdot z_{new}}
\end{align*}
$$
因为 $z_{new} = z_{id}\cdot cos\theta + z_{90}\cdot sin\theta$,  且$z_{id}$与$z_{90}$为一组标准正交基， 故 $z_{id} \cdot z_{new} = \|z_{id}\| \cdot \|z_{new}\| \cdot cos\theta=cos\theta$, 综上$M^{-1}(z_{new}, p, d) = z_{id} $.

Conclusion:
- 可以学习这篇文章中对id的修改和复原的方法
- About attribute-identity decoupling method，maybe the encoder in《Face Anonymization by Manipulating Decoupled Identity Representation》that decouples attribute & identity simultaneously is better.

# 《Privacy-Preserving Face Recognition with Learnable Privacy Budgets in Frequency Domain》

Keywords: Privacy-preserving, face recognition, differential privacy

Drawbacks:
- Homomorphic encryption: maintain a high level of recognition accuracy but high computational consumption
- PEEP(using differential privacy):low computational complexity but low recognition performance

Motivation: 
- 保护后的图像identity能够让face recognition model完成训练任务，且无法得到原始图像 (Differential Privacy)
- 将图像通过DCT转换到frequency domain，再将与identity无关的direct component channel去除

Pipeline:
source image RGB (W, H, 3) -> YCbCr -> 8-fold Up-sampling -> BDCT -> frequency domain (W, H, 8, 8, 3) -> remove DC channel -> Differential privacy module

Details:

- Frequency-Domain Transformation Module
  - 研究表明人类只依靠low-frequency domain来区别图像,而神经网路是同时依靠low- and high-frequency information, 所以可以减少使用low-frequency information是隐私保护的一个好方法。分离方法就是采用DCT transformation
- Differential privacy module
  - 在privacy budget $\epsilon$不变的情况下，通过face recognition model的loss来学习representation中每个位置的budget $\epsilon_{i,j,k}$

启发：如果训练网络的数据集具需要高度隐私则可以使用差分隐私的方法

# 《EfficientPhys: Enabling Simple, Fast and Accurate Camera-Based Cardiac Measurement》

Contributions:
- 提出了两个end-to-end并且分别基于CNN和Transformer的检测模型
- 在对视频帧序列进行检测时无需进行预处理(one-stop)

Method:
- Normalization Module
  - difference layer: 提取帧间差异(torch.diff)，通过这个方式减少环境光和人体运动所产生的噪声，保留PPG的微小变化
  - batch-normalization layer: (1)防止帧间差异的规模(scale)不同；(2)batchnorm在归一化后的affine过程中学习两个参数$\beta, \gamma$，可以让模型在训练过程中学习放大PPG产生的差异而缩小noise造成的差异
- Self-Attention-Shifted Network (Convolutional module)
  - To capture the rich spatial-temporal information efficiently, using self-attention block after two tensor-shifted convolutions(TSM: Temporal Shift Module for Efficient Video Understanding).
  - self-attention模块可以减少temporal shifting产生的负面影响以及运动和光线产生的噪声
- Transformer-based model
  - 2D Swin-transformer + temporal shifted module

Dataset:
- Train: AFRL + synthetic avatar video dataset
- Test: UBFC, PURE and MMSE