---
title: '2023/10/30, Week 8'
date: 2023-10-30
permalink: /posts/2023/10/week8/
tags:
  - GAN Inversion
---

# GAN Inversion

GAN inversion aims to invert a given image back into the latent space of a pretrained GAN model. The image can be faithfully reconstructed from the inverted code by the generator of GAN.

### Methods

- learning-based approach: train an encoder to map an image into the latent space.
  - drawbacks:
    -  sometimes fail in preserving identities as well as some other details when reconstructing face images
- optimization-based approach: directly train the latent code like trainable parameters by back-propagation.
  - drawbacks:
    - higher computational cost
    - it needs a suitable initialization strategy.
- hybrid approach: initialize the latent code with an encoder and refine it with an optimization algorithm.

# 《Designing an Encoder for StyleGAN Image Manipulation》

### Terminology

$\mathcal{W} \in \mathbb{R}^{512}$ is the learned latent space of StyleGAN.

|                   | Individual style codes are limited to $\mathcal{W}$ | Same style code in all layers |
| ----------------- | :-------------------------------------------------: | :---------------------------: |
| $\mathcal{W}$     |                    $\checkmark$                     |         $\checkmark$          |
| $\mathcal{W}^k$   |                    $\checkmark$                     |                               |
| $\mathcal{W}_*$   |                                                     |         $\checkmark$          |
| $\mathcal{W}_*^k$ |                                                     |                               |

### Distortion-Editability and Distortion-Perception Trade-offs

$\mathcal{W}_*^k$ achieves lower distortion. But $\mathcal{W}$ is more editable and has better perceptual quality.

### Designing an encoder

![](D:\桌面文件\组会PPT_ljn\第8周\distribution of latent space.png)

#### Minimize Variation

Encourage the inferred $\mathcal{W}_*^k$ to lie closer to $\mathcal{W}_*$.

-  To get $E(x) = (w_0,w_1, \dots , W_{N-1})$, we infer a single latent code $w$, and a set of offset from $w$ , so the output is $E(x) = (w_0,w_1 + \Delta_1, \dots , W_{N-1} + \Delta_{N-1})$

- Add a $L_2$ delta-regularization loss to enforce a proximity to $\mathcal{W}_*$ :
  $$
  \begin{equation*}
  \mathcal{L}_{d-reg}~(W) = \sum^{N-1}_{i=1} \| \Delta_i \|_2.
  \end{equation*}
  $$
  

#### Minimize Deviation from $\mathcal{W}^k$

Second step - make $\mathcal{W}_*^k$ closer to $\mathcal{W}^k$. 

- adopt **a latent discriminator** which is trained in an adversarial manner to discriminate between real samples from the $\mathcal{W}$ space (generated by StyleGAN’s mapping function) and the encoder’s learned $W_*$ space.

# 《**StyleSpace Analysis: Disentangled Controls for StyleGAN Image Generation**》

#### Disentanglement metric: Attribute Dependency (AD)

Attribute Dependency measures the degree to which manipulation along a certain direction induces changes in other attributes, as *measured by classifiers* for those attributes
