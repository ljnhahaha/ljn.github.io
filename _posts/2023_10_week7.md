---
title: '2023/10/23, Week 7'
date: 2023-10-23
permalink: /posts/2023/10/week7/
tags:
  - Privacy-Preserving
  - Face recognition
---

# 《ArcFace: Additive Angular Margin Loss for Deep Face Recognition》

### Keywords

Face recognition, geodesic distance

### Motivation & Method

The last dot product between the feature vector and the last fully connected layer is equal to the cosine distance after feature and weight normalization.
$$
\begin{align*}
W^T_j x_i = \|W_j\|\ \|x_i\| \cos{\theta_j}
\end{align*}
$$
where $W \in \mathbb{R}^{d \times n}$ denotes the weight of last MLP layer, $W_j$ denotes the $j$-th column of the $W$, $x_i$ denotes the feature of $i$-th sample belonging to the $y_i$-th class. We fix the $\|W_j\| = \|x_j\| = 1$, then $W^T_j x_i = \cos{\theta_j}$.

Original Softmax loss:
$$
\begin{equation*}
\mathcal{L}_{orig} = - \frac{1}{N} \sum_{n=1}^{N} \log{\frac{e^{W^T_{y_i} x_i + b_{y_{i}}}}{\sum^{n}_{j=1} e^{W^T_j x_i} + b_j}},
\end{equation*}
$$
Rescale $\|x_i\|$ to $s$. Now it could be:
$$
\begin{equation*}
\mathcal{L} = - \frac{1}{N} \sum_{n=1}^{N} \log{\frac{e^{s \cos{\theta_{y_i}}}}{e^{s\cos{\theta_{y_i}}} + \sum^{n}_{j=1,j\ne y_i} e^{s\cos{\theta_j}}}}
\end{equation*}
$$
To enhance the intra-class (类内) compactness and inter-class (类间) discrepancy, we add an additive angular margin penalty $m$ between $x_i$ and $W_{y_i}$. The final ArcFace is
$$
\begin{equation*}
\mathcal{L}_{Arc} = - \frac{1}{N} \sum_{n=1}^{N} \log{\frac{e^{s \cos{(\theta_{y_i} + m)}}}{e^{s\cos{(\theta_{y_i} + m)}} + \sum^{n}_{j=1,j\ne y_i} e^{s\cos{\theta_j}}}}
\end{equation*}
$$



# 《**DartBlur: Privacy Preservation with Detection Artifact Suppression**》

### Keywords

Blur

### Motivation

Blur-based privacy-preserving methods are simple to implement but introduce additional noise and artifacts.

GAN-based Face-swap:

- resort to keypoint detector, which are prone to errors
- it is cumbersome to check the performance.
- rely on real data during training, which may raise concerns about privacy protection.

Goals:

- Accessibility: 不需要其他模型来引导训练
- Review convenience: 能很快区分是否去识别
- Detection artifact suppression: 减少blur对检测器的影响

### Methodology

Let $x \in \mathbb{R}^{3 \times h \times w}$ represents the original image $b \in \mathbb{R}^{3 \times h \times w}$ denotes the binary mask based on ground-truth bounding box. Let $g$ represent the blur function, and $g(x,b)$ represent the blurred image.
$$
\begin{equation*}
g(x, b) = x~\odot~(1-b) + \tilde{g}(\mathcal{G}(x,b))~\odot~b
\end{equation*}
$$
Four objectives:

- for review convenience:
  $$
  \begin{align*}
  \mathcal{L}_{rev} &= \mathcal{L}_{rev}(g, x, b, \epsilon_{rev}) \\
                    &= \max{(\| g(x,b) - \mathcal{G}(x,b) \|_1 - \epsilon_{rev},0)}
  \end{align*}
  $$
  
- for detection artifact suppression:
  $$
  \begin{align}
  \mathcal{L}_{oper} &= \mathcal{L}_{det}\left( f(g(x,b)), f(x)\right), \\
  \mathcal{L}_{post} &= \mathcal{L}_{det}\left( f_g(g(x,b)), f(x)\right), \\
  \mathcal{L}_{cyc} &= \mathcal{L}_{det}\left( f_g(x), f(x)\right),
  \end{align}
  $$
