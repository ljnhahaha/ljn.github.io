---
title: '2023/10/16, Week 6'
date: 2023-10-16
permalink: /posts/2023/10/week6/
tags:
  - Privacy-Preserving
  - Video Steganography
---

# 《DPE: Disentanglement of Pose and Expression for General Video Portrait Editing》

Keywords: talking face generation

Motivation:
- 之前的方法无法在换脸的同时将脸部表情和姿态分离，又因为通常的处理方法是将脸部截取后输入网络再贴会去，这会导致最后的图像中存在明显的人工痕迹(artifacts)
- 针对lack of paired data，采用unsupervised方法，并通过bidirectional cyclic training method来约束

# 《Large-capacity and Flexible Video Steganography via Invertible Neural Network》

### Keywords: 
video steganography, frequency domain

### Contributes:

- large-capacity: hide/recover multiple (up to 7) secret videos in/from a cover video.
- flexibility: a key-controllable scheme; scalable strategy

### Method:

Forward hiding: secret videos $\rm{x}_{se} = \{\rm{x}_{se}(n) \}^{N_s}_{n=1}$ + a cover video $\rm{x}_{co}$ -> a stego video (隐写后的视频结果) $\rm{x}_{st}$

Frequency concatenate:
$$
\rm{X} \in \mathbb{R}^{L \times 3 \times W \times H} \xrightarrow{DWT} \rm{X} \in \mathbb{R}^{4L \times 3 \times \frac{W}{2} \times \frac{H}{2}} \xrightarrow{concatenate} \rm{X} \in \mathbb{R}^{12L \times \frac{W}{2} \times \frac{H}{2}}
$$
DWT transform can separate the low-frequency and high-frequency sub-bands.

Recovering: a channel-wise broadcasting operation $\mathbb{R}^{3 \times W \times H} \xrightarrow{copy} \mathbb{R}^{3L \times W \times H}$ (discard the redundancy information in the forward hiding), then multiple secret videos are recovered in parallel. Because of the INN, the forward and backward share the same model architecture and parameters.

Redundancy Prediction Module: utilize random Gaussian noise as redundancy information lacks data specificity and adaptivity, so predict the redundancy information. Moreover, we can construct key-controllable video steganography by injecting conditional information into the RPM.

Scalable Embedding Module:
To handle the case where there are different number of secret videos hidden in a cover video, we truncate a convolution kernel $\widetilde{\rm{M}} \in \mathbb{R}^{C_{in} \times C_{out} \times k \times k}$ from $ \rm{M} \in \mathbb{R}^{C \times C_{out} \times k \times k} $. (Q: 为什么只对从$\rm{X}_{se}$到$\rm{X}_{co}$做scale?)

### Metrics:
**PSNR(Peak Signal-to-Noise Ratio)**:
Given a noise-free $m \times n$ image $I$ and its noisy approximation $K$:
$$
\begin{align*}
    MSE &= \frac{1}{mn} \sum^{m-1}_{i=0} \sum^{n-1}_{j=0}[I(i, j) - K(i, j)]^2 \\
    PSNR &= 10 \cdot \log_{10}{(\frac{MAX^2_I}{MSE})}
\end{align*}
$$

Typical values for the PSNR in lossy image and video compression are between 30 and 50 dB, provided the bit depth is 8 bits, where higher is better.

# 《**RiDDLE: Reversible and Diversified De-identification with Latent Encryptor**》

### Keywords:

de-identification, latent encryption, decryption

### Method:

- Gan Inversion: Embedding an existing image into the latent space of a pretrained generator. (See "Image2StyleGAN: How to Embed Images Into the StyleGAN Latent Space?" for details)
  - Optimization based methods: regard latent codes as trainable parameters and iteratively update their value by minimizing several loss terms.
  - Encoder based methods: train a encoder to learn the mapping from image to the latent manifold.
  
- Encrypt and decrypt: process the latent code and the password by a transformer-based encryptor (cross-attention), and use the same network as the decryptor. (Q: How about using INN ?)

  - identity diversity loss:

    there exist $m$ passwords for identity encryption and each password has another $n$ wrong passwords for decryption, and all $m \times (n+1)$ passwords used for encryption and incorrect decryption are unique: 
    $$
    \begin{equation*}
    \mathcal{M}_{ij} = \max{(\epsilon, \cos{F_e(\rm{x}^i), F_e(\rm{x}^j)}))},
    \end{equation*}
    $$
    where $F_e$ denotes a pretrained Arcface network, and $\epsilon$ represents a predefined similarity threshold which is set to 0 in all the experiments.


### Metric:

**Known Factor Feature Angle (KFFA): ** 
